# Design Process

## Key Concepts  
- **User-Centered Design (UCD)**: an iterative design process where teams involve users at every phase to create highly usable and accessible products by focusing on user needs (Slides 9)  
- **Human-Centered Design (HCD)**: approach defined by ISO 9241-210 that aims to make systems usable and useful by applying human factors/ergonomics and usability knowledge, enhancing effectiveness, satisfaction, accessibility, and counteracting adverse effects on health and performance (Slides 10)  
- **Usability**: the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context (ISO 9241) (Slides 11)  

## HCD Process (ISO 9241-210)  
1. **Understand** (Specify context of use): identify primary users, their goals, requirements, and usage environment via observations, interviews, focus groups (Slides 12)  
2. **Define** (Specify user requirements): translate findings into concrete requirements, personas, antipersonas, and scenarios to guide design (Slides 16)  
3. **Design/Implement** (Design solutions): iterate prototypes—from low-fidelity sketches and storyboards to high-fidelity interactive wireframes, software, hardware, and fabricated mock-ups (Slides 21)  
4. **Evaluate** (Evaluate against requirements): measure how real users interact using quantitative (lab/field studies, surveys) and qualitative (thematic analysis) methods (Slides 35)  

---

## 1. Understand (Context of Use)  
- **Ethnography**: immerse in users’ real environments; methods include participant observation and interviews; early in process to uncover unexpected issues (Slides 13)  
- **Interviews**:  
  - *Structured*: fixed questions, closed responses, easy to analyze quantitatively (Slides 14)  
  - *Semi-structured*: mix of predetermined and emergent topics for depth + flexibility (Slides 14)  
  - *Unstructured*: free-flowing, open questions to surface novel insights (Slides 14)  
  - *Interviewer Effect*: interviewer identity can bias responses; mitigate by neutrality and limited disclosure (Slides 15)  
- **Focus Groups**: group interviews to leverage dynamics; pros—depth, comfort, efficiency; cons—social biases, topic drift (Slides 16)  

---

## 2. Define (User Requirements)  
- **Requirements Specification**: list functionalities and metrics reflecting user needs (e.g., connection speed, ease of administration) (Slides 16)  
- **Personas**: fictional archetypes based on research to represent key user types and their goals (goal-directed, role-based, engaging) (Slides 17)  
- **Antipersonas**: characterize users for whom the design is *not* intended, to highlight scope (Slides 18)  
- **Scenarios**: story-based descriptions of how personas achieve goals in context; include background, motivations, tasks, environment, challenges (Slides 19)  

---

## 3. Design/Implement (Prototyping)  

### Low-Fidelity Prototypes  
- **Sketches**: quick, rough drawings to explore ideas; focus on interaction over artistry (Slides 22)  
- **Storyboards**: sequence of sketches showing screen states and transitions (Slides 23)  
- **Paper Prototypes**: interactive paper mock-ups using cut-outs or dynamic overlays; useful for early user testing (Slides 24)  
- **Wizard-of-Oz**: simulated functionality (e.g., voice UI) with a hidden human “wizard” controlling responses (Slides 25)  

### High-Fidelity Prototypes  
- **Interactive Wireframes**: clickable digital layouts using tools like Figma or Adobe XD to explore visual design and workflows (Slides 26)  
- **Software Prototypes**: working code (e.g., Unity3D, Android Studio) to test interactions and reveal implementation challenges (Slides 27)  
- **Hardware Prototypes**: microcontroller-based mock-ups (Arduino, Raspberry Pi) to explore physical behaviors (Slides 28)  
- **Digital Fabrication**: rapid production of parts (3D printing, laser cutting) for casing or mechanical components (Slides 29)  

---

## 4. Evaluate (Against Requirements)  

### Quantitative Methods  
- **Lab Study**: controlled comparison of interfaces; watch for unknown variables, ordering effects, and recruit appropriately (Slides 37)  
- **Field Study**: observe real-world use under natural conditions (Slides 37)  
- **Surveys**: questionnaires to gather large-scale user feedback (Slides 37)  
- **Experimental Design**:  
  - *Hypothesis*: falsifiable statement (e.g., “New system launches faster than Zoom+streaming”) (Slides 39)  
  - *Independent Variable (IV)* and *Dependent Variable (DV)* definitions (Slides 39)  
  - *Validity & Reliability*: ensure internal/external validity and repeatability (Slides 42)  
  - *Between- vs. Within-Subjects*: trade-offs in sample size and ordering biases (Slides 43)  

### Qualitative Methods  
- **Thematic Analysis**: code transcripts, identify themes, review and report insights to explain *why* differences occur (Slides 45)  

---

## Extensions & Critiques  

### Criticism of HCD  
- Claim: major technologies often emerge without formal HCD; raises questions about its role in radical innovation (Norman, 2005) (Slides 47)  

### Design Thinking  
- **Definition**: non-linear, iterative approach to tackle “wicked” problems through empathy, problem reframing, ideation, prototyping, and testing (Slides 48)  
- **Properties**: deep human focus, diverse process models (3–7 steps), emphasis on radical innovation (Slides 49)  

### Ideation Methods  
- **Brainstorming**: group idea generation with “no bad ideas,” thematic grouping, and voting (Slides 51)  
- **Worst Possible Idea**: invert problem by listing terrible solutions, then reverse attributes to spark creativity (Slides 52)  
- **Ideation Hexagon**: six tactics (generalize, combine, invert, amplify, reduce, alternate) to systematically generate novel concepts (Slides 53)  

---

## Process Models Comparison  
- Despite varied terminology (HCD, Design Thinking, Double Diamond, IDEO), most models decompose into four core stages: **Analyse → Define → Design → Finalise** (Slides 54)  
